# Scraping Module

Este m贸dulo se encarga de extraer (scrapear) ofertas de trabajo de LinkedIn y volcarlas en un CSV y en la base de datos.

---

##  Estructura

```
scraping/
 config.py # Ajustes y credenciales (pydantic Settings)
 driver.py # Inicializaci贸n y login de Selenium
 scraper.py # L贸gica de extracci贸n con BeautifulSoup
 to_db.py # Carga del CSV en la base de datos via repositorio
 utils.py # Funciones auxiliares (conteo de aplicantes, normalizaci贸n de URL)
```

##  Uso

### Ejecutar pipeline completo

```bash
python -m scraping.pipeline
```

Esto:
- Arranca Selenium (headless Chrome)
- Hace login en LinkedIn
- Desplaza la p谩gina para cargar hasta JOB_LIMIT resultados
- Extrae campos y guarda dataset_linkedin.csv
- Volca el CSV a la base de datos configurada

##  Campos extra铆dos

| Campo | Descripci贸n |
|-------|-------------|
| title | T铆tulo de la oferta. Ej: "Python Developer" |
| company | Nombre de la empresa. Ej: "Capgemini" |
| location | Ubicaci贸n geogr谩fica. Ej: "Nueva York, Estados Unidos" |
| date_posted | Fecha ISO de publicaci贸n. Ej: 2025-04-30 |
| days_since_posted | D铆as transcurridos desde date_posted hasta hoy |
| job_url | URL can贸nica de la oferta (sin par谩metros de tracking) |
| applicants | N煤mero de aplicantes reportados en la p谩gina de la oferta |

##  Elecci贸n de tecnolog铆as

**Selenium + headless Chrome**:
- LinkedIn carga los listados y el bot贸n "Ver m谩s" mediante JavaScript, por lo que requests + BeautifulSoup no obtendr铆a el HTML completo.

**BeautifulSoup**:
- Una vez renderizada la p谩gina por Selenium, se parsea el DOM est谩tico con BS4 para extraer selectores CSS de forma sencilla y robusta.

**Pandas**:
- Para normalizar y volcar los datos a CSV.

**SQLAlchemy + repositorio (to_db.py)**:
- Para hacer un upsert eficiente en la base de datos relacional.

##  Consideraciones

**Respeto a robots.txt y t茅rminos de uso**:
- No est谩 permitida la descarga masiva de informaci贸n. Este scraper introduce retrasos (SCRAPE_DELAY) entre acciones para simular un uso humano.

**Configuraci贸n por entorno**:
- Todos los par谩metros (credenciales, timeouts, l铆mites) son variables de entorno gestionadas con Pydantic Settings.